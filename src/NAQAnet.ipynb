{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline for DROP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import importlib\n",
    "import allennlp\n",
    "\n",
    "\n",
    "from allennlp.models.reading_comprehension.naqanet import NumericallyAugmentedQaNet\n",
    "from allennlp.data.dataset_readers.reading_comprehension.drop import DropReader\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.matrix_attention.bilinear_matrix_attention import BilinearMatrixAttention\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DropReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reader._read(\"../data/drop_dataset/drop_dataset_dev.json\")\n",
    "dev = reader._read(\"../data/drop_dataset/drop_dataset_dummy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19072/19072 [00:02<00:00, 8150.79it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train + dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "lstm2 = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "attn = BilinearMatrixAttention(EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NumericallyAugmentedQaNet(vocab, word_embeddings, 2, lstm1, attn, lstm2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "iterator = BucketIterator(batch_size=2, sorting_keys=[(\"passage\", \"num_tokens\")])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train,\n",
    "                  validation_dataset=dev,\n",
    "                  patience=10,\n",
    "                  num_epochs=1000,\n",
    "                  cuda_device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "em: 0.0084, f1: 0.0163, loss: 1960995.6629 ||: 100%|██████████| 4768/4768 [18:34<00:00,  4.78it/s]\n",
      "em: 0.0090, f1: 0.0220, loss: 1960995.3151 ||: 100%|██████████| 4768/4768 [03:52<00:00,  3.92it/s]\n",
      "em: 0.0381, f1: 0.0714, loss: 1960995.0116 ||: 100%|██████████| 4768/4768 [18:06<00:00,  5.60it/s]\n",
      "em: 0.0428, f1: 0.1006, loss: 1960994.3583 ||: 100%|██████████| 4768/4768 [03:44<00:00,  4.14it/s]\n",
      "em: 0.0549, f1: 0.0933, loss: 1960994.6337 ||: 100%|██████████| 4768/4768 [17:30<00:00,  4.54it/s]\n",
      "em: 0.0521, f1: 0.1126, loss: 1960994.2154 ||: 100%|██████████| 4768/4768 [03:34<00:00,  4.25it/s]\n",
      "em: 0.0673, f1: 0.1102, loss: 1960994.3408 ||: 100%|██████████| 4768/4768 [17:06<00:00,  4.98it/s]\n",
      "em: 0.0788, f1: 0.1218, loss: 1960993.9575 ||: 100%|██████████| 4768/4768 [03:38<00:00,  4.33it/s]\n",
      "em: 0.0749, f1: 0.1182, loss: 1960994.2264 ||: 100%|██████████| 4768/4768 [17:16<00:00,  4.71it/s]\n",
      "em: 0.0236, f1: 0.0551, loss: 1960995.3339 ||: 100%|██████████| 4768/4768 [03:39<00:00,  4.21it/s]\n",
      "em: 0.0239, f1: 0.0495, loss: 2021281.2435 ||:  16%|█▌        | 752/4768 [02:46<19:16,  3.47it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
